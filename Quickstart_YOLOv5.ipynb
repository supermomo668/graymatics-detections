{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syl8xE0TNO7S",
        "outputId": "9e24451e-3a13-410f-9560-de3dba1990d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15814, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 15814 (delta 9), reused 22 (delta 2), pack-reused 15769\u001b[K\n",
            "Receiving objects: 100% (15814/15814), 14.59 MiB | 19.81 MiB/s, done.\n",
            "Resolving deltas: 100% (10823/10823), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "%pip install onnx Pillow opencv-python onnxruntime-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA9MRO2xMlH5",
        "outputId": "0670262e-889b-4920-d5ca-2c55005fc43f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5/yolov5\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.11.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "import torch, numpy as np, cv2, requests\n",
        "from PIL import Image\n",
        "# import utils\n",
        "# display = utils.notebook_init()  # checks"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMusP4OAxFu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4582f52a-c54d-4bd9-eb71-9c518ae0a67e"
      },
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5n.pt', force_reload=True)  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "im_save_pth = f\"./{im.split('/')[-1]}\"\n",
        "    # download image\n",
        "img_data = requests.get(im).content\n",
        "with open(im_save_pth, 'wb') as handler:\n",
        "    handler.write(img_data)\n",
        "# infer results\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ðŸš€ 2023-7-22 Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to yolov5n.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.87M/3.87M [00:00<00:00, 75.6MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
            "Adding AutoShape... \n",
            "image 1/1: 720x1280 2 persons, 1 tie\n",
            "Speed: 429.3ms pre-process, 10.0ms inference, 1.8ms NMS per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export model as onnx\n",
        "!python export.py --weights \"./yolov5n.pt\" --include onnx --dynamic\n",
        "model_onnx = torch.hub.load('./', 'custom', path='yolov5n.onnx', source='local', force_reload = True)"
      ],
      "metadata": {
        "id": "nBU57tF0vrVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = np.asarray(Image.open(im_save_pth))\n",
        "print(im.shape)"
      ],
      "metadata": {
        "id": "8I5dkjCsNTHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_onnx(im)  # inference\n",
        "results.print()"
      ],
      "metadata": {
        "id": "Z63rYiYDKcsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_video= 'test_video_t30-35s.avi'\n",
        "!python detect.py --weights yolov5n.onnx --conf 0.25 --source '{input_video}'\n",
        ""
      ],
      "metadata": {
        "id": "9e-88SuKvAmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15glLzbQx5u0"
      },
      "source": [
        "# 4. Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    }
  ]
}